{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "048cf799",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T00:10:48.504759Z",
     "start_time": "2023-06-28T00:10:46.591412Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883d2644",
   "metadata": {},
   "source": [
    "# Posterior Predictive Distributions for Stochastic Predictions  \n",
    "\n",
    "Suppose one is interested in parameter estimation for a theoretical model $y_\\text{th}$ that depends on a set of parameters $\\vec{a}$.\n",
    "Upon finding the posterior $\\text{pr}(\\vec{a} \\,|\\, y_\\text{exp})$, it can be useful to look at the distribution of $y_\\text{th}(\\vec{a})$ across the posterior distribution of $\\vec{a}$.\n",
    "This is given by the posterior predictive distribution (PPD)\n",
    "$$\n",
    "    \\text{pr}(y_\\text{th} \\,|\\, y_\\text{exp}) = \\int d\\vec{a} \\,\\text{pr}(y_\\text{th} \\,|\\, \\vec{a}, y_\\text{exp}) \\,\\text{pr}(\\vec{a} \\,|\\, y_\\text{exp})\n",
    "$$\n",
    "\n",
    "If the theory is determined exactly from the parameters $\\vec{a}$, then one is able to write $\\text{pr}(y_\\text{th} \\,|\\, \\vec{a}, y_\\text{exp}) = \\text{pr}(y_\\text{th} \\,|\\, \\vec{a})$, **but this is not always the case**.\n",
    "One example of a PPD that cannot be simplified in this way is the PPD for the theoretical discrepancy:\n",
    "$$\n",
    "    \\text{pr}(y_\\text{th} + \\delta y_\\text{th} \\,|\\, y_\\text{exp})\n",
    "$$\n",
    "where\n",
    "$$\n",
    "    y_\\text{exp} = y_\\text{th} + \\delta y_\\text{th} + \\delta y_\\text{exp}.\n",
    "$$\n",
    "The discrepancy $\\delta y_\\text{th}$ is generally unknown, and so it is given a distribution.\n",
    "A common prior is to state that the discrepancy follows a Gaussian process (GP) with some kernel $\\kappa$\n",
    "$$\n",
    "    \\delta y_\\text{th}(x) \\sim GP[0, \\kappa(x, x')],\n",
    "$$\n",
    "where it is assumed that $\\delta y_\\text{th}$ is independent of the parameters $\\vec{a}$.\n",
    "Because $\\delta y_\\text{th}$ is **not** uniquely determined by $\\vec{a}$, then the experimental data **does** have an impact on $\\text{pr}(y_\\text{th} + \\delta y_\\text{th} \\,|\\, \\vec{a}, y_\\text{exp})$, which is in fact the *conditional* probability density for the Gaussian process.\n",
    "\n",
    "We can illustrate this using an example, inspired by the model proposed in [this](#MelendezGP) reference.\n",
    "For the theory (and the discrepancy), we will consider a simple geometric series whose coefficients are to be determined.\n",
    "These coefficients will play the role of $\\vec{a}$.\n",
    "The series, which constitute $y_\\text{th}$, will be terminated at some order $k$, and the subsequent terms will be placed in $\\delta y_\\text{th}$, aka, the truncation error.\n",
    "Note that, although the coefficients in the geometric series are treated as constants, this case generalizes nicely to when the coefficients are themselves Gaussian processes.\n",
    "\n",
    "**NOTE:** For simplicity, no interpolation is done in this notebook. If we wanted to interpolate between the experimental data points, this feature could be easily added.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeb7474",
   "metadata": {},
   "source": [
    "## Fit Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d1b1ff",
   "metadata": {},
   "source": [
    "This is a linear model and so we can use the standard linear regression equations to find the posterior distribution\n",
    "$$\n",
    "    \\vec{a} \\,|\\, y_{\\text{exp}} \\sim N[\\mu_a, \\Sigma_a] \\\\\n",
    "    \\mu_a = \\Sigma_a X^T (\\Sigma_\\text{th} + \\Sigma_\\text{exp})^{-1} y_\\text{exp} \\\\\n",
    "    \\Sigma_a = [X^T (\\Sigma_\\text{th} + \\Sigma_\\text{exp})^{-1} X]^{-1}\n",
    "$$\n",
    "This equation follows from the well known (Bayesian) linear model.\n",
    "More general relations are given [here](#MelendezGP), in Eqs. (A27)-(A28)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e54e441",
   "metadata": {},
   "source": [
    "## PPD Calculation\n",
    "\n",
    "The PPD for the theory prediction can be calculated analytically. If $y_\\text{th} = X \\vec{a}$, then\n",
    "$$\n",
    "  y_\\text{th} \\,|\\, y_\\text{exp} \\sim N[X\\mu_a, X \\Sigma_a X^T]\n",
    "$$\n",
    "This follows from Eq. (A35) in [this](#MelendezGP) reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b554a64",
   "metadata": {},
   "source": [
    "The PPD when including truncation error is slightly trickier, but still analytic.\n",
    "Now the PPD is given by\n",
    "$$\n",
    "    \\text{pr}(y_\\text{th} + \\delta y_\\text{th} \\,|\\, y_\\text{exp}) = \\int d\\vec{a} \\,\\text{pr}(y_\\text{th} + \\delta y_\\text{th} \\,|\\, \\vec{a}, y_\\text{exp}) \\,\\text{pr}(\\vec{a} \\,|\\, y_\\text{exp})\n",
    "$$\n",
    "The prior of $y_\\text{th} + \\delta y_\\text{th}$ is itself a GP\n",
    "$$\n",
    "    y_\\text{th} + \\delta y_\\text{th} \\,|\\, \\vec{a} \\sim GP[y_\\text{th}(\\vec{a}), \\kappa(x, x')].\n",
    "$$\n",
    "With this understanding, it is clear that\n",
    "$$\n",
    "    \\text{pr}(y_\\text{th} + \\delta y_\\text{th} \\,|\\, \\vec{a}, y_\\text{exp})\n",
    "$$\n",
    "is the conditional PDF for the GP.\n",
    "Thus, we compute conditional GP equations *first*, and then sum over all $\\vec{a}$.\n",
    "The conditional GP equations are well known.\n",
    "They can be found, e.g., [here](#MelendezGP) in Eqs. (10)-(15). Once the conditional GP is given as a function of $\\vec{a}$,\n",
    "$$\n",
    "    y_\\text{th} + \\delta y_\\text{th} \\,|\\, \\vec{a}, y_\\text{exp} \\sim N[Z\\vec{a} + \\Sigma_\\text{th} (\\Sigma_\\text{th} + \\Sigma_\\text{exp})^{-1} y_\\text{exp},\\,\\, \\Sigma_\\text{th} + \\Sigma_\\text{th} (\\Sigma_\\text{th} + \\Sigma_\\text{exp})^{-1}\\Sigma_\\text{th}] \\\\\n",
    "    Z = X - \\Sigma_\\text{th} (\\Sigma_\\text{th} + \\Sigma_\\text{exp})^{-1} X\n",
    "$$\n",
    "then they can be integrated out as done above (again, see Eq. (A35) [here](#MelendezGP)). In this case, this yields\n",
    "$$\n",
    "y_\\text{th} + \\delta y_\\text{th} \\,|\\, y_\\text{exp} \\sim N[Z\\mu_a + \\Sigma_\\text{th} (\\Sigma_\\text{th} + \\Sigma_\\text{exp})^{-1} y_\\text{exp},\\,\\, \\Sigma_\\text{th} + \\Sigma_\\text{th} (\\Sigma_\\text{th} + \\Sigma_\\text{exp})^{-1}\\Sigma_\\text{th} + Z\\Sigma_a Z^T]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb8f400",
   "metadata": {},
   "source": [
    "## Non-PPD Calculation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a01f29",
   "metadata": {},
   "source": [
    "Although not the PPD, it is sometimes useful to look at the distribution of $y_\\text{th} + \\delta y_\\text{th}$ sampled over our posterior values for $\\vec{a}$. So rather than conditioning $y_\\text{th} + \\delta y_\\text{th}$ on the experimental values, we instead use its unconditional distribution. This quantity can be described as\n",
    "$$\n",
    "    y_\\text{th} + \\delta y_\\text{th} \\, | \\, I_{\\vec{a} \\,|\\, y_\\text{exp}}\n",
    "$$\n",
    "where $I_{\\vec{a} \\,|\\, y_\\text{exp}}$ is the information about the posterior distribution of $\\vec{a}$.\n",
    "By integrating in $\\vec{a}$, we have\n",
    "$$\n",
    "    \\text{pr}(y_\\text{th} + \\delta y_\\text{th} \\, | \\, I_{\\vec{a} \\,|\\, y_\\text{exp}})\n",
    "    = \\int d\\vec{a}\\, \\text{pr}(y_\\text{th} + \\delta y_\\text{th} \\, | \\, \\vec{a}) \\text{pr}(\\vec{a} \\,|\\, I_{\\vec{a} \\,|\\, y_\\text{exp}}),\n",
    "$$\n",
    "where the factor on the left is the unconditional GP, and the factor on the right is the posterior density for $\\vec{a}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e6bf3e",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* <a id=\"MelendezGP\" /> Melendez, J. A., Furnstahl, R. J., Phillips, D. R., Pratola, M. T. & Wesolowski, S. Quantifying correlated truncation errors in effective field theory. Phys Rev C 100, 044001 (2019)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ed1d6d",
   "metadata": {},
   "source": [
    "## Interface using ipywidgets with interactive_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee2a3542",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T00:10:48.735977Z",
     "start_time": "2023-06-28T00:10:48.517690Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the widgets we will use (add more as needed!)\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox, Layout, Tab, Label, Checkbox\n",
    "from ipywidgets import FloatSlider, IntSlider, Play, Dropdown, HTMLMath\n",
    "\n",
    "from IPython.display import display\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3aad13c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T00:10:48.747967Z",
     "start_time": "2023-06-28T00:10:48.738232Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.stats import (\n",
    "    linear_feature_matrix,\n",
    "    linear_theory_prediction,\n",
    "    linear_theory_covariance,\n",
    "    linear_solve,\n",
    "    conditional_gp,\n",
    "    linear_conditional_covariance_from_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "708e6167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T00:10:48.770670Z",
     "start_time": "2023-06-28T00:10:48.766806Z"
    }
   },
   "outputs": [],
   "source": [
    "def master_plot(\n",
    "    y_th_flag=True,\n",
    "    y_true_flag=True,\n",
    "    y_exp_flag=True,\n",
    "    y_th_ppd_flag=True,\n",
    "    y_tot_ppd_flag=True,\n",
    "    y_non_ppd_flag=True,\n",
    "    rng_coeff_seed=3,\n",
    "    rng_data_seed=3,\n",
    "    N_exp=50,\n",
    "    N_int=100,\n",
    "    k_max=7,\n",
    "    k=3,\n",
    "    cbar=1.0,\n",
    "    sd_exp=0.2,\n",
    "    data_min=0.01,\n",
    "    data_max=0.9,\n",
    "    x_min=0,\n",
    "    x_max=1.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Does the calculations then generates the plot of results.\n",
    "\n",
    "        Parameters:\n",
    "        k_max (int): Total max order, including truncation error; (default: 7)\n",
    "        k (int): Max order in y_th; (default: 3)\n",
    "        rng_seed (int): Seed for random number generator; (default: 3)\n",
    "        N (int): Number of data to use in training; (default: 50)\n",
    "        cbar (float): Standard deviation of the parameters; (default: 1)\n",
    "        sd_exp (float): Experimental standard deviation; (default: 0.2)\n",
    "\n",
    "        Returns:\n",
    "        fig (matplotlib Figure): plot of results\n",
    "    \"\"\"\n",
    "    # Recalculate everything\n",
    "\n",
    "    # Parameters and data generation\n",
    "    y_ref = 1  # A constant scalar that multiplies the series\n",
    "    x_exp = np.linspace(\n",
    "        data_min, data_max, N_exp\n",
    "    )  # The ratio x^n in the geometric series\n",
    "    x_int = np.linspace(x_min, x_max, N_int)\n",
    "    higher_orders = np.arange(k, k_max)  # These are in the truncation error\n",
    "    orders = np.arange(k)  # These are in y_th\n",
    "\n",
    "    # Make everything repeatable but separate coefficient and data random numbers\n",
    "    rng_coeff = np.random.default_rng(rng_coeff_seed)\n",
    "    rng_data = np.random.default_rng(rng_data_seed)\n",
    "\n",
    "    # The coefficients of the geometric series\n",
    "    c_true_all = rng_coeff.normal(0, cbar, k_max)\n",
    "    c_true_higher = c_true_all[k:]\n",
    "    c_true = c_true_all[:k]\n",
    "\n",
    "    # Set up toy predictions and experiment\n",
    "    X_old = linear_feature_matrix(x=x_exp, y_ref=y_ref, orders=orders)\n",
    "    X_new = linear_feature_matrix(x=x_int, y_ref=y_ref, orders=orders)\n",
    "    X_old_higher = linear_feature_matrix(x=x_exp, y_ref=y_ref, orders=higher_orders)\n",
    "    X_new_higher = linear_feature_matrix(x=x_int, y_ref=y_ref, orders=higher_orders)\n",
    "\n",
    "    y_th = linear_theory_prediction(X=X_old, c=c_true)\n",
    "    dy_th = linear_theory_prediction(X=X_old_higher, c=c_true_higher)\n",
    "    dy_exp = rng_data.normal(0, sd_exp, N_exp)\n",
    "    y_exp = y_th + dy_th + dy_exp\n",
    "\n",
    "    y_th_int = linear_theory_prediction(X=X_new, c=c_true)\n",
    "    dy_th_int = linear_theory_prediction(X=X_new_higher, c=c_true_higher)\n",
    "\n",
    "    # Fit coefficients\n",
    "    Sigma_th_oo = linear_theory_covariance(\n",
    "        x=x_exp, xp=x_exp, y_ref=y_ref, cbar=cbar, orders=higher_orders\n",
    "    )\n",
    "    Sigma_th_no = linear_theory_covariance(\n",
    "        x=x_int, xp=x_exp, y_ref=y_ref, cbar=cbar, orders=higher_orders\n",
    "    )\n",
    "    Sigma_th_nn = linear_theory_covariance(\n",
    "        x=x_int, xp=x_int, y_ref=y_ref, cbar=cbar, orders=higher_orders\n",
    "    )\n",
    "    Sigma_exp = sd_exp ** 2 * np.eye(N_exp)\n",
    "    c_mean, c_inv_cov = linear_solve(X=X_old, y=y_exp, cov=Sigma_th_oo + Sigma_exp)\n",
    "\n",
    "    # PPD calculation\n",
    "    y_th_ppd_mean = linear_theory_prediction(X=X_new, c=c_mean)\n",
    "    y_th_ppd_mean_exp = linear_theory_prediction(X=X_old, c=c_mean)\n",
    "    y_th_ppd_stdv = np.sqrt(np.diag(X_new @ np.linalg.solve(c_inv_cov, X_new.T)))\n",
    "\n",
    "    y_tot_ppd_mean, y_tot_ppd_cov = conditional_gp(\n",
    "        y=y_exp,\n",
    "        mean_new=y_th_ppd_mean,\n",
    "        mean_old=y_th_ppd_mean_exp,\n",
    "        Sigma_nn=Sigma_th_nn,\n",
    "        Sigma_no=Sigma_th_no,\n",
    "        Sigma_oo=Sigma_th_oo + Sigma_exp,\n",
    "    )\n",
    "    y_tot_ppd_cov += linear_conditional_covariance_from_parameters(\n",
    "        X_new=X_new,\n",
    "        X_old=X_old,\n",
    "        Sigma_no=Sigma_th_no,\n",
    "        Sigma_oo=Sigma_th_oo + Sigma_exp,\n",
    "        precision=c_inv_cov,\n",
    "    )\n",
    "    y_tot_ppd_stdv = np.sqrt(np.diag(y_tot_ppd_cov))\n",
    "\n",
    "    # non-PPD calculation\n",
    "    y_th_non_ppd_stdv = np.sqrt(np.diag(Sigma_th_nn)) + np.sqrt(\n",
    "        np.diag(X_new @ np.linalg.solve(c_inv_cov, X_new.T))\n",
    "    )\n",
    "\n",
    "    # make the plot\n",
    "    fig, ax = plt.subplots(figsize=(5, 4.4))\n",
    "\n",
    "    if y_th_flag:\n",
    "        ax.plot(x_int, y_th_int, label=\"y_th (True)\", c=\"k\")\n",
    "\n",
    "    if y_true_flag:\n",
    "        ax.plot(\n",
    "            x_int, y_th_int + dy_th_int, label=\"y_th + dy_th (True)\", c=\"k\", ls=\"--\"\n",
    "        )\n",
    "\n",
    "    if y_exp_flag:\n",
    "        ax.errorbar(\n",
    "            x_exp,\n",
    "            y_exp,\n",
    "            sd_exp,\n",
    "            lw=0,\n",
    "            elinewidth=1,\n",
    "            barsabove=True,\n",
    "            capsize=1,\n",
    "            label=\"y_exp\",\n",
    "            c=\"C1\",\n",
    "        )\n",
    "\n",
    "    if y_th_ppd_flag:\n",
    "        ax.plot(x_int, y_th_ppd_mean, c=\"r\")\n",
    "        ax.fill_between(\n",
    "            x_int,\n",
    "            y_th_ppd_mean + y_th_ppd_stdv,\n",
    "            y_th_ppd_mean - y_th_ppd_stdv,\n",
    "            label=\"y_th PPD\",\n",
    "            color=\"r\",\n",
    "            alpha=0.3,\n",
    "        )\n",
    "\n",
    "    if y_tot_ppd_flag:\n",
    "        ax.plot(x_int, y_tot_ppd_mean, c=\"g\", zorder=0)\n",
    "        ax.fill_between(\n",
    "            x_int,\n",
    "            y_tot_ppd_mean + y_tot_ppd_stdv,\n",
    "            y_tot_ppd_mean - y_tot_ppd_stdv,\n",
    "            label=\"y_th + dy_th PPD\",\n",
    "            color=\"g\",\n",
    "            alpha=0.3,\n",
    "            zorder=0,\n",
    "        )\n",
    "\n",
    "    if y_non_ppd_flag:\n",
    "        ax.plot(x_int, y_th_ppd_mean, c=\"b\")\n",
    "        ax.fill_between(\n",
    "            x_int,\n",
    "            y_th_ppd_mean + y_th_non_ppd_stdv,\n",
    "            y_th_ppd_mean - y_th_non_ppd_stdv,\n",
    "            label=\"y_th + dy_th Non-PPD\",\n",
    "            color=\"b\",\n",
    "            alpha=0.3,\n",
    "        )\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"x\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "169a3365",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T00:10:49.245466Z",
     "start_time": "2023-06-28T00:10:48.770198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16db15d552a641389a292bb2871e2fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='Which plots: ', layout=Layout(width='90px')), Checkbâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Widgets for the various inputs.\n",
    "#   For any widget, we can set continuous_update=False if we don't want the\n",
    "#    plots to shift until the selection is finished (particularly relevant for\n",
    "#    sliders).\n",
    "\n",
    "# Widgets for the plot choice (plus a label out front)\n",
    "plot_choice_w = Label(value=\"Which plots: \", layout=Layout(width=\"90px\"))\n",
    "\n",
    "\n",
    "def plot_choice_widget(on=True, plot_description=None):\n",
    "    \"\"\"Makes a Checkbox to select whether to show a plot.\"\"\"\n",
    "    return Checkbox(\n",
    "        value=on,\n",
    "        description=plot_description,\n",
    "        disabled=False,\n",
    "        indent=False,\n",
    "        layout=Layout(width=\"150px\"),\n",
    "    )\n",
    "\n",
    "\n",
    "y_th_flag_w = plot_choice_widget(True, r\"$y_{\\rm th}$ (true)\")\n",
    "y_true_flag_w = plot_choice_widget(True, r\"$y_{\\rm th} + \\delta y_{\\rm th}$ (true)\")\n",
    "y_exp_flag_w = plot_choice_widget(True, r\"$y_{\\rm exp}$\")\n",
    "y_th_ppd_flag_w = plot_choice_widget(True, r\"$y_{\\rm th}$ ppd\")\n",
    "y_tot_ppd_flag_w = plot_choice_widget(True, r\"$y_{\\rm th} + \\delta y_{\\rm th}$ ppd\")\n",
    "y_non_ppd_flag_w = plot_choice_widget(\n",
    "    False, r\"$y_{\\rm th} + \\delta y_{\\rm th}$ non-ppd\"\n",
    ")\n",
    "\n",
    "# Widgets for the model parameters (all use FloatSlider or IntSlider, so made functions)\n",
    "def float_widget(value, min, max, step, description, format):\n",
    "    \"\"\"Makes a FloatSlider with the passed parameters and continuous_update\n",
    "    set to False.\"\"\"\n",
    "    slider_border = Layout(border=\"solid 1.0px\")\n",
    "    return FloatSlider(\n",
    "        value=value,\n",
    "        min=min,\n",
    "        max=max,\n",
    "        step=step,\n",
    "        disabled=False,\n",
    "        description=description,\n",
    "        continuous_update=False,\n",
    "        orientation=\"horizontal\",\n",
    "        layout=slider_border,\n",
    "        readout=True,\n",
    "        readout_format=format,\n",
    "    )\n",
    "\n",
    "\n",
    "def int_widget(value, min, max, step, description):\n",
    "    \"\"\"Makes a FloatSlider with the passed parameters and continuous_update\n",
    "    set to False.\"\"\"\n",
    "    slider_border = Layout(border=\"solid 1.0px\")\n",
    "    return IntSlider(\n",
    "        value=value,\n",
    "        min=min,\n",
    "        max=max,\n",
    "        step=step,\n",
    "        disabled=False,\n",
    "        description=description,\n",
    "        continuous_update=False,\n",
    "        orientation=\"horizontal\",\n",
    "        layout=slider_border,\n",
    "        readout=True,\n",
    "        readout_format=\"d\",\n",
    "    )\n",
    "\n",
    "\n",
    "rng_coeff_seed_w = int_widget(\n",
    "    value=3, min=0, max=100, step=1, description=r\"$\\delta y_{\\rm th}$ seed\"\n",
    ")\n",
    "rng_data_seed_w = int_widget(\n",
    "    value=3, min=0, max=100, step=1, description=r\"$\\delta y_{\\rm exp}$ seed\"\n",
    ")\n",
    "\n",
    "N_data_w = int_widget(value=50, min=2, max=100, step=1, description=r\"$N_{\\rm data}$\")\n",
    "N_interp_w = int_widget(value=100, min=2, max=200, step=1, description=r\"$N_{\\rm interp}$\")\n",
    "\n",
    "k_max_w = int_widget(value=7, min=2, max=10, step=1, description=r\"$k_{\\rm max}$\")\n",
    "k_w = int_widget(value=3, min=2, max=5, step=1, description=r\"theory order\")\n",
    "\n",
    "cbar_w = float_widget(\n",
    "    value=1.0, min=0.1, max=5.0, step=0.1, description=r\"$\\overline c$:\", format=\".1f\"\n",
    ")\n",
    "sd_exp_w = float_widget(\n",
    "    value=0.2,\n",
    "    min=0.001,\n",
    "    max=2.0,\n",
    "    step=0.1,\n",
    "    description=r\"$\\sigma_{\\rm exp}$:\",\n",
    "    format=\".2f\",\n",
    ")\n",
    "data_min_w = float_widget(\n",
    "    value=0.01,\n",
    "    min=0.01,\n",
    "    max=0.5,\n",
    "    step=0.1,\n",
    "    description=r\"data $x_{\\rm min}$:\",\n",
    "    format=\".2f\",\n",
    ")\n",
    "data_max_w = float_widget(\n",
    "    value=0.9,\n",
    "    min=0.3,\n",
    "    max=2.0,\n",
    "    step=0.1,\n",
    "    description=r\"data $x_{\\rm max}$:\",\n",
    "    format=\".1f\",\n",
    ")\n",
    "\n",
    "\n",
    "# Widgets for the plotting parameters\n",
    "x_min_w = float_widget(\n",
    "    value=-0.05,\n",
    "    min=0,\n",
    "    max=0.5,\n",
    "    step=0.1,\n",
    "    description=r\"Pred $x_{\\rm min}$:\",\n",
    "    format=\".1f\",\n",
    ")\n",
    "x_max_w = float_widget(\n",
    "    value=1.0,\n",
    "    min=0.5,\n",
    "    max=5.0,\n",
    "    step=0.1,\n",
    "    description=r\"Pred $x_{\\rm max}$:\",\n",
    "    format=\".1f\",\n",
    ")\n",
    "\n",
    "# Widgets for the styling parameters\n",
    "font_size_w = Dropdown(\n",
    "    options=[\"12\", \"16\", \"18\", \"20\", \"24\"],\n",
    "    value=\"18\",\n",
    "    description=\"Font size:\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    layout=Layout(width=\"140px\"),\n",
    ")\n",
    "\n",
    "empty_w = Label(value=\" \", layout=Layout(width=\"300px\", border=\"solid 1.0px\"))\n",
    "\n",
    "\n",
    "############## Begin: Explicit callback functions #######################\n",
    "\n",
    "# Make sure that x_max for plotting is at least x_min + 1\n",
    "def update_plot_max(*args):\n",
    "    if x_max_w.value < x_min_w.value:\n",
    "        x_max_w.value = x_min_w.value + 1\n",
    "\n",
    "\n",
    "x_min_w.observe(update_plot_max, \"value\")\n",
    "x_max_w.observe(update_plot_max, \"value\")\n",
    "\n",
    "\n",
    "# Make sure that data_max is at least data_min + .1\n",
    "def update_data_max(*args):\n",
    "    if data_max_w.value < data_min_w.value:\n",
    "        data_max_w.value = data_min_w.value + 0.1\n",
    "\n",
    "\n",
    "data_max_w.observe(update_data_max, \"value\")\n",
    "data_min_w.observe(update_data_max, \"value\")\n",
    "\n",
    "\n",
    "############## End: Explicit callback functions #######################\n",
    "\n",
    "# Set up the interactive_output widget\n",
    "plot_out = widgets.interactive_output(\n",
    "    master_plot,\n",
    "    dict(\n",
    "        y_th_flag=y_th_flag_w,\n",
    "        y_true_flag=y_true_flag_w,\n",
    "        y_exp_flag=y_exp_flag_w,\n",
    "        y_th_ppd_flag=y_th_ppd_flag_w,\n",
    "        y_tot_ppd_flag=y_tot_ppd_flag_w,\n",
    "        y_non_ppd_flag=y_non_ppd_flag_w,\n",
    "        rng_coeff_seed=rng_coeff_seed_w,\n",
    "        rng_data_seed=rng_data_seed_w,\n",
    "        N_exp=N_data_w,\n",
    "        N_int=N_interp_w,\n",
    "        k_max=k_max_w,\n",
    "        k=k_w,\n",
    "        cbar=cbar_w,\n",
    "        sd_exp=sd_exp_w,\n",
    "        data_min=data_min_w,\n",
    "        data_max=data_max_w,\n",
    "        x_min=x_min_w,\n",
    "        x_max=x_max_w,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Now do some manual layout, where we can put the plot anywhere using plot_out\n",
    "hbox1 = HBox(\n",
    "    [\n",
    "        plot_choice_w,\n",
    "        y_th_flag_w,\n",
    "        y_true_flag_w,\n",
    "        y_exp_flag_w,\n",
    "        y_th_ppd_flag_w,\n",
    "        y_tot_ppd_flag_w,\n",
    "        y_non_ppd_flag_w,\n",
    "    ]\n",
    ")  #  choice of what plots\n",
    "hbox2 = HBox([N_data_w, rng_coeff_seed_w, rng_data_seed_w, empty_w])  #\n",
    "hbox3 = HBox([k_max_w, k_w, cbar_w, sd_exp_w])  # initial conditions and damping\n",
    "hbox4 = HBox([data_min_w, data_max_w, x_min_w, x_max_w])  # time and plot ranges\n",
    "hbox5 = HBox([font_size_w])  # font size\n",
    "\n",
    "# We'll set up Tabs to organize the controls.  The Tab contents are declared\n",
    "#  as tab0, tab1, ... (probably should make this a list?) and the overall Tab\n",
    "#  is called tab (so its children are tab0, tab1, ...).\n",
    "tab_height = '70px'  # Fixed minimum height for all tabs. Specify another way?\n",
    "tab0 = VBox([hbox2, hbox3], layout=Layout(min_height=tab_height))\n",
    "tab1 = VBox([hbox1, hbox4], layout=Layout(min_height=tab_height))\n",
    "tab2 = VBox([hbox5], layout=Layout(min_height=tab_height))\n",
    "\n",
    "tab = Tab(children=[tab0, tab1, tab2])\n",
    "tab.set_title(0, \"Parameters & Data\")\n",
    "tab.set_title(1, \"Plotting\")\n",
    "tab.set_title(2, \"Styling\")\n",
    "\n",
    "param_height = \"120px\"\n",
    "param_box = VBox([hbox1, hbox2, hbox3, hbox4], layout=Layout(min_height=param_height))\n",
    "\n",
    "# Release the Kraken!\n",
    "vbox2 = VBox([param_box, plot_out])\n",
    "display(vbox2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f3d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5859df2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}