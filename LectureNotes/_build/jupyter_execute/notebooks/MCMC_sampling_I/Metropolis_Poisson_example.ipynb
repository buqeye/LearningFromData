{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Metropolis-Hasting MCMC sampling of a Poisson distribution \n",
    "\n",
    "This notebook was adapted from Example 1, section 12.2 in Gregory's *Bayesian Logical Data Analysis for the Physical Sciences*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The Poisson discrete random variable from scipy.stats is defined by (see [documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html))\n",
    "\n",
    "$$\n",
    "p(k|\\mu) = \\frac{\\mu^k e^{-\\mu}}{k!} \\quad \\mbox{for }k\\geq 0 \\;.\n",
    "$$\n",
    "\n",
    "where $k$ is an integer and $\\mu$ is called the shape parameter. The mean and variance of this distribution are both equal to $\\mu$. (Note: Gregory uses a different notation, but we'll stay consistent with scipy.stats.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "By \"sampling a Poisson distribution\" we mean we will obtain a set of $k$ values: $\\{k_1, k_2, k_3, \\ldots\\}$ that follow this distribution.  That is, for a particular $k_i$, the probability to get that value should be what we get by evaluating $p(k_i|\\mu)$. We know we've succeeded if we make a histogram of our set of $k_i$s and it looks like $p(k|\\mu)$ (scaled to line up or else our histogram needs to be normalized to one).\n",
    "\n",
    "The method we'll use is generically called Markov chain Monte Carlo or MCMC.  A Markov chain starts with some initial value, and then each successive value is generated from the previous one.  But it is not deterministic: when the new value is chosen, there is a random number involved.  The particular version of MCMC used here is called Metropolis-Hasting. You may be familiar with this from a statistical mechanics class, where it is typically applied to the Ising model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We'll do the Metropolis-Hasting sampling as follows:\n",
    "1. Choose an initial $k$ (call it $k_0$), having already fixed $\\mu$.\n",
    "2. Given $k_i$, sample a uniform random number $x$ from 0 to 1 (so $x \\sim U(0,1)$) and propose $k' = k_i + 1$ if the $x > 0.5$, otherwise propose $k' = k_i - 1$.\n",
    "3. Compute the Metropolis ratio $r = p(k'|\\mu)\\, /\\, p(k_i|\\mu)$ using the discrete Poisson distribution.\n",
    "4. Given another uniform random number $y \\sim U(0,1)$, $k_{i+1} = k'$ if $y \\leq r$, else $k_{i+1} = k_i$ (i.e., keep the same value for the next $k$).\n",
    "5. Repeat 2.-4. until you think you have enough samples of $k$.\n",
    "6. When graphing the posterior or calculating averages, skip the first values until the sampling has equilibrated (this is generally called the \"burn-in\" or \"warm-up\").\n",
    "\n",
    "In practice we'll carry this out by generating all our uniform random numbers at the beginning using `scipy.stats.uniform.rvs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "from math import factorial\n",
    "\n",
    "# We'll get our uniform distributions from stats, but there are other ways.\n",
    "import scipy.stats as stats  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set() # for nicer plot formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def poisson(k, mu):\n",
    "    \"\"\"\n",
    "    Returns a Poisson distribution value for k with mean mu\n",
    "    \"\"\"\n",
    "    return mu**k * np.exp(-mu) / factorial(k) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the following we have the steps 1-6 defined above marked in the code. *Step through the implementation and ask questions about what you don't understand.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Set mu and k0\n",
    "mu = 3.\n",
    "k0 = 100    \n",
    "\n",
    "num_steps = 1000  # number of MCMC steps we'll take\n",
    "# generate the two sets of uniform random numbers we'll need for 2. and 4.\n",
    "uniform_1 = stats.uniform.rvs(size=num_steps)  \n",
    "uniform_2 = stats.uniform.rvs(size=num_steps)\n",
    "\n",
    "k_array = np.zeros(num_steps, dtype=int)\n",
    "k_array[0] = k0\n",
    "\n",
    "# 5. Loop through steps 2-4\n",
    "for i in range(num_steps-1):  # num_steps-1 so k_array[i+1] is always defined\n",
    "    # 2. Propose a step\n",
    "    k_now = k_array[i]\n",
    "    if uniform_1[i] > 0.5:\n",
    "        kp = k_now + 1          # step to the right\n",
    "    else:\n",
    "        kp = max(0, k_now - 1)  # step to the left, but don't go below zero\n",
    "    \n",
    "    # 3. Calculate Metropolis ratio\n",
    "    metropolis_r = poisson(kp, mu) / poisson(k_now, mu)\n",
    "    # 4. Accept or reject\n",
    "    if uniform_2[i] <= metropolis_r:\n",
    "        k_array[i+1] = kp\n",
    "    else:\n",
    "        k_array[i+1] = k_now\n",
    "\n",
    "# 6. Choose how many steps to skip\n",
    "warm_up_steps = 500\n",
    "\n",
    "# Set up for side-by-side plots\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "# Plot the trace (that means k_i for i=0 to num_steps)\n",
    "ax_trace = fig.add_subplot(2, 1, 1)    \n",
    "ax_trace.plot(range(num_steps), k_array, color='blue')\n",
    "ax_trace.set_ylim(0, 12)\n",
    "ax_trace.set_xlabel(r'$i$')\n",
    "ax_trace.set_ylabel(r'$k_i$')\n",
    "trace_title = rf'MCMC trace for Poisson distribution with $\\mu = ${mu:.1f}'\n",
    "ax_trace.set_title(trace_title)\n",
    "\n",
    "# Plot the Poisson distribution\n",
    "ax_plot = fig.add_subplot(2, 1, 2)\n",
    "bin_num = 12\n",
    "n_pts = range(bin_num)\n",
    "    \n",
    "# Scale exact result to the histogram, accounting for warm_up_steps    \n",
    "poisson_pts = [(num_steps - warm_up_steps) * poisson(n, mu) for n in n_pts]     \n",
    "    \n",
    "# Plot the exact distribution    \n",
    "ax_plot.plot(n_pts, poisson_pts, marker='o', color='black') \n",
    "# Histogram k_i beyond the warm-up period\n",
    "ax_plot.hist(k_array[warm_up_steps:], bins=n_pts,\n",
    "             align='left', rwidth=0.2, color='red')\n",
    "ax_plot.set_xlim(-1, bin_num)\n",
    "ax_plot.set_xlabel(r'$k$')\n",
    "plot_title = rf'$\\mu = ${mu:.1f}  # steps = {num_steps:d},' \\\n",
    "               + f' # warm-up steps = {warm_up_steps:d}'\n",
    "ax_plot.set_title(plot_title)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*What do you observe about these plots?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Check the mean and standard deviations from the samples against exact\n",
    "print(f' MCMC mean = {np.mean(k_array[warm_up_steps:]):.2f}')\n",
    "print(f'Exact mean = {stats.poisson.mean(mu=mu):.2f}')\n",
    "print(f'   MCMC sd = {np.std(k_array[warm_up_steps:]):.2f}')\n",
    "print(f'  Exact sd = {stats.poisson.std(mu=mu):.2f}')      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Questions and things to do\n",
    "\n",
    "*How do you expect the accuracy of the estimate of the mean scales with the number of points? How would you test it?*\n",
    "<br/><br/><br/>\n",
    "\n",
    "*Record values of the MCMC mean for `num_steps` = 1000, 4000, and 16000, running each 10-20 times.  Explain what you find.* \n",
    "<br/><br/><br/>\n",
    "\n",
    "*Calculate the mean and standard deviations of the means you found (using `np.mean()` and `np.std())`.  Explain your results.*\n",
    "<br/><br/><br/>\n",
    "\n",
    "*Predict what you will find from 10 runs at `num_steps` = 100,000.  What did you actually find?*\n",
    "<br/><br/><br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}