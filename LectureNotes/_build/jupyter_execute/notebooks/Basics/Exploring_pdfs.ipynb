{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exploring PDFs\n",
    "\n",
    "**Goals:** To play with plots of probability density functions (pdfs) using the `scipy.stats` and `numpy` libraries. \n",
    "Work through the notebook but don't just follow the instructions.  Explore!\n",
    "\n",
    "**Answer the questions in** *italics*. **Check with your neighbors and ask for help if you get stuck or are unsure.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quick overview: To a Bayesian, everything is a pdf (probability density function)\n",
    "\n",
    "Physicists are used to dealing with pdfs as normalized wave functions squared.  For a one-dimensional particle, the probability density at $x$ is\n",
    "\n",
    "<span style=\"color: red\">\n",
    "\n",
    " $$\n",
    " |\\Psi(x)|^2 \\Longrightarrow p(x) \n",
    " $$\n",
    "\n",
    "</span> \n",
    "\n",
    "The *probability* of finding $x$ in some interval $a \\leq x \\leq b$ is found by integration:\n",
    "\n",
    "<span style=\"color: red\">\n",
    "    \n",
    " $$\n",
    " p(a \\leq x \\leq b) = \\int_a^b |\\Psi(x)|^2 \\; dx \n",
    " $$\n",
    "\n",
    "</span> \n",
    "\n",
    "\n",
    "Just as with \"Lagrangian\" vs. \"Lagrangian density\", physicists are not always careful when saying probability vs. probability density.\n",
    "\n",
    "Physicists are also used to multidimensional normalized pdfs as wave functions squared, e.g. probability density for particle 1 at $x_1$ and particle 2 at $x_2$:\n",
    "\n",
    "<span style=\"color: red\">\n",
    "\n",
    " $$\n",
    " |\\Psi(x_1, x_2)|^2 \\Longrightarrow p(x_1,x_2) \\equiv p(\\textbf{x})  \n",
    "   \\quad \\mbox{with}\\quad \\textbf{x} \n",
    " \\equiv \\{x_1,x_2\\}\n",
    " $$\n",
    "\n",
    "</span> \n",
    "\n",
    "<span style=\"color:black\">(Note that you will find alternative notation in the physics and statistics literature for generic pdfs: $p(\\textbf{x}) = P(\\textbf{x}) = \\textrm{pr}(\\textbf{x}) = \\textrm{prob}(\\textbf{x}) = \\ldots$ )</span>\n",
    "\n",
    "Some other vocabulary and definitions:\n",
    "* $p(x_1,x_2)$ is the <em>joint probability density</em> of $x_1$ and $x_2$.\n",
    "* What is the probability to find particle 1 at $x_1$ and particle 2 anywhere?  $\\color{blue}{\\int\\! |\\Psi(x_1,x_2)|^2 dx_2}$ (integrated over the full domain of $x_2$, e.g., 0 to $\\infty$).\n",
    "* The <em>marginal probability density</em> of $x_1$ is: \n",
    "$\\color{blue}{p(x_1) = \\int\\! p(x_1,x_2)\\,dx_2}$.\n",
    "* \"Marginalizing\" = \"integrating out\" (eliminates from the posterior the \"nuisance parameters\" whose value you don't care about). \n",
    "\n",
    "In Bayesian statistics there are pdfs (or pmfs if discrete) for experimental <i>and</i> theoretical uncertainties, fit parameters, hyperparameters (what are those?), events (\"Will it rain tomorrow?\"), etc.  Even if $x$ has the definite value $x_0$, we can use the pdf $p(x) = \\delta(x-x_0)$. \n",
    "\n",
    "*Questions?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# set up for plots in this notebook using matplotlib \n",
    "# [Note: this is not generally necessary anymore with Jupyter notebooks as it is the default.]\n",
    "%matplotlib inline   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats  # We'll use stats as our source of pdfs\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import corner  # for making \"corner plots\" showing 2-dimensional posteriors\n",
    "\n",
    "import seaborn as sns; sns.set()  # nicer plots!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualization of pdfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Quick introduction to  `scipy.stats`\n",
    "\n",
    "If you google \"scipy.stats\", you'll likely get the manual page as the first hit: [https://docs.scipy.org/doc/scipy/reference/stats.html ].  Here you'll find a long list of the continuous and discrete distributions that are available, followed (scroll way down) by many different methods (functions) to extract properties of a distribution (called \"Summary Statistics\") and do many other statistical tasks.\n",
    "\n",
    "Follow the link for any of the distributions (your choice!) to find its mathematical definition, some examples of how to use it, and a list of methods. Some methods of interest to us here:\n",
    "* mean() - Mean of the distribution.\n",
    "* median() - Median of the distribution.\n",
    "* pdf(x) - Value of the probability density function at x.\n",
    "* rvs(size=num_pts) - generate num_pts random values of the pdf.\n",
    "* interval(alpha) - Endpoints of the range that contains alpha percent of the distribution.\n",
    "\n",
    "*Try out some of the examples* (cut-and-paste from the manual page after turning off the >>>s by clicking in the upper right of a box).  We'll use all of these methods in explicit examples below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Matplotlib plotting helper functions\n",
    "\n",
    "We first define a few functions that we'll use to extract and plot quantities of interest. \n",
    "\n",
    "*After you've looked at the examples that follow, come back and make sure you know what the functions are doing.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def dist_stuff(dist):\n",
    "    \"\"\"\n",
    "    Finds the median, mean, and 68%/95% credible intervals for the given \n",
    "    1-d distribution (which is an object from scipy.stats).  \n",
    "    \"\"\"\n",
    "    # For x = median, then mean: return x and the value of the pdf at x as a list\n",
    "    median = [dist.median(), dist.pdf(dist.median())]  \n",
    "    mean = [dist.mean(), dist.pdf(dist.mean())]\n",
    "    # The left and right limits of the credibility interval are returned\n",
    "    cred68 = dist.interval(0.68)  # 68% interval\n",
    "    cred95 = dist.interval(0.95)  # 95% interval\n",
    "    return median, mean, cred68, cred95\n",
    "\n",
    "def dist_mode(dist, x):\n",
    "    \"\"\"\n",
    "    Return the mode (maximum) of the 1-d distribution for array x. \n",
    "    \"\"\"\n",
    "    x_max_index = dist.pdf(x).argmax()\n",
    "    # Return x of the maximum and the value of the pdf at that x \n",
    "    mode = [x[x_max_index], dist.pdf(x[x_max_index])]\n",
    "    return mode\n",
    "\n",
    "def dist_plot(ax, dist_label, x_dist, dist, color='blue'):\n",
    "    \"\"\"\n",
    "    Plot the distribution, indicating median, mean, mode\n",
    "    and 68%/95% probability intervals on the axis that is passed (ax).\n",
    "    \"\"\"\n",
    "    median, mean, cred68, cred95 = dist_stuff(dist) \n",
    "    mode = dist_mode(dist, x_dist)\n",
    "    \n",
    "    ax.plot(x_dist, dist.pdf(x_dist), label=dist_label, color=color)    \n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('p(x)')\n",
    "    \n",
    "    # Point to the median, mode, and mean with arrows (adjusting the spacing)\n",
    "    text_x = 0.2*(x_dist[-1] - x_dist[0])\n",
    "    text_x_mid = (x_dist[-1] + x_dist[0]) / 2.\n",
    "    text_y = mode[1]*1.15\n",
    "    ax.annotate('median', xy=median, xytext=(text_x_mid+text_x, text_y),\n",
    "                arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "    ax.annotate('mode', xy=mode, xytext=(text_x_mid-text_x, text_y),\n",
    "                arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "    ax.annotate('mean', xy=mean, xytext=(text_x_mid, text_y),\n",
    "                arrowprops=dict(facecolor='blue', shrink=0.05))\n",
    "    \n",
    "    # Mark the credible intervals using shading (with appropriate alpha)\n",
    "    ax.fill_between(x_dist, 0, dist.pdf(x_dist), \n",
    "                    where=((x_dist > cred68[0]) & (x_dist < cred68[1])), \n",
    "                    facecolor='blue', alpha=0.2)\n",
    "    ax.fill_between(x_dist, 0, dist.pdf(x_dist), \n",
    "                    where=((x_dist > cred95[0]) & (x_dist < cred95[1])), \n",
    "                    facecolor='blue', alpha=0.1)\n",
    "    \n",
    "    ax.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some standard pdfs: normal and beta distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Make some standard plots: normal, beta\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "# Standard normal distribution -- try changing the mean and std. dev. \n",
    "x_norm = np.linspace(-4, 4, 500) \n",
    "mu = 1       # mean\n",
    "sigma = 2.0  # standard deviation\n",
    "norm_dist = stats.norm(mu, sigma) # the normal distribution from scipy.stats\n",
    "norm_label='normal pdf' + '\\n' + rf'$\\mu=${mu:1.1f}' \\\n",
    "             + '\\n' + rf'$\\sigma=${sigma:1.1f}' \n",
    "ax1 = fig.add_subplot(1,3,1)  # first of three subplots\n",
    "dist_plot(ax1, norm_label, x_norm, norm_dist)\n",
    "\n",
    "# beta distribution, characterized by a and b parameters\n",
    "x_beta = np.linspace(-0.1, 1.1, 500)  # beta ranges from 0 to 1 \n",
    "a1 = 2\n",
    "b1 = 1\n",
    "beta_dist = stats.beta(a1, b1)  # the beta distribution from scipy.stats\n",
    "beta1_label='beta pdf' + '\\n' + rf'$a=${a1:1.1f}' \\\n",
    "              + '\\n' + rf'$b=${b1:1.1f}'\n",
    "ax2 = fig.add_subplot(1,3,2)  # second of three subplots\n",
    "dist_plot(ax2, beta1_label, x_beta, beta_dist)\n",
    "\n",
    "# another beta distribution\n",
    "#x_beta = np.linspace(-0.1, 1.1, 500)\n",
    "a2 = 1\n",
    "b2 = 1\n",
    "beta2_dist = stats.beta(a2, b2)\n",
    "beta2_label='beta pdf' + '\\n' + rf'$a=${a2:1.1f}' \\\n",
    "              + '\\n' + rf'$b=${b2:1.1f}' \n",
    "ax3 = fig.add_subplot(1,3,3)  # third of three subplots\n",
    "dist_plot(ax3, beta2_label, x_beta, beta2_dist)\n",
    "\n",
    "mu2 = beta2_dist.mean()\n",
    "sigma2 = beta2_dist.std()\n",
    "norm2_dist = stats.norm(mu2, sigma2)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The 68%/95% probability regions are shown in dark/light shading.  When applied to Bayesian posteriors, these are known as <em>credible intervals</em> or DoBs (degree of belief intervals) or Bayesian confidence intervals. The horizontal extent on the $x$-axis translates into the vertical extent of the error bar or error band for $x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The values of the mode, mean, median can be used as *point estimates* for the \"probable\" value of $x$.  \n",
    "*If you had a symmetric bimodal distribution, what point estimate would be best?  Or are they all poor?* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Things to try:\n",
    "* Change the normal (Gaussian) distribution so that it has a different mean and standard deviation.\n",
    "* Add another plot to one of the graphs. E.g., generate a normal distribution with the same mean and about the same width as the beta distribution with $a=10$, $b=10$ and add it to that plot.  You don't need to call a special function, just use `norm2_dist = stats.norm(mu2, sigma2)` with your guesses for the $\\mu$ and $\\sigma$ values and then `ax3.plot(x_beta, norm2_dist.pdf(x_beta), color='red')` to overlay the curve on `ax3`.  \n",
    "* Try some other distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Another standard class of pdf:  Student t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*Find the functional definition on the `scipy.stats` web page for the t distribution.  Is it consistent with the plots?*\n",
    "\n",
    "*What are the `loc` and `scale` parameters?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Make some plots of the Student t distribution\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "x_t = np.linspace(-5, 5, 500)\n",
    "\n",
    "norm1_dist = stats.norm(0.,1.)  # a normal distribution for comparison\n",
    "\n",
    "nu1 = 1.01\n",
    "t1_dist = stats.t(nu1) # the Student t distribution\n",
    "t1_label='t pdf' + '\\n' + rf'$\\nu=${nu1:1.1f}'\n",
    "ax1 = fig.add_subplot(1,3,1)\n",
    "dist_plot(ax1, t1_label, x_t, t1_dist)\n",
    "#ax1.plot(x_t, norm1_dist.pdf(x_t), color='red')\n",
    "\n",
    "nu2 = 3\n",
    "t2_dist = stats.t(nu2) # the Student t distribution\n",
    "t2_label = 't pdf' + '\\n' + rf'$\\nu=${nu2:1.1f}'\n",
    "ax2 = fig.add_subplot(1,3,2)\n",
    "dist_plot(ax2, t2_label, x_t, t2_dist)\n",
    "#ax2.plot(x_t, norm1_dist.pdf(x_t), color='red')\n",
    "\n",
    "nu3 = 100\n",
    "t3_dist = stats.t(nu3) # the Student t distribution\n",
    "t3_label = 't pdf' + '\\n' + rf'$\\nu=${nu3:1.1f}'\n",
    "ax3 = fig.add_subplot(1,3,3)\n",
    "dist_plot(ax3, t3_label, x_t, t3_dist)\n",
    "#ax3.plot(x_t, norm1_dist.pdf(x_t), color='red')\n",
    "\n",
    "var2 = t2_dist.var()\n",
    "\n",
    "print(f'variance for nu2: {var2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note the \"heavy tails\" in the t distribution as $\\nu$ gets small.  As $\\nu$ gets large, the distribution approaches a standard normal (Gaussian) distribution.\n",
    "\n",
    "*Try superposing a normal pdf on each.*  (The code is already there, just commented out, but make sure you understand what the statements are doing.)\n",
    "\n",
    "*What is the variance of each of the t distributions (use the `var` method)?  Any surprises?* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Projected posterior plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here we use the [corner package](https://corner.readthedocs.io/en/latest/api.html) to make some projected posterior plots. (Note: there are other choices to make these plots but corner is really fast.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# examples of corner plots\n",
    "ndim, nsamples = 2, 1000000\n",
    "#np.random.seed(42)\n",
    "# generate some synthetic data from a normal distribution\n",
    "mu, sigma = 0., 1.\n",
    "norm_samples = stats.norm.rvs(size=ndim * nsamples, loc=mu, scale=sigma).reshape([nsamples, ndim])\n",
    "\n",
    "figure1 = corner.corner(norm_samples, \n",
    "                        labels=[r\"$x$\", r\"$y$\", r\"$\\log \\alpha$\"],\n",
    "                        quantiles=[0.16, 0.5, 0.84],\n",
    "                        show_titles=True, title_kwargs={\"fontsize\": 12})\n",
    "ax = figure1.get_axes()\n",
    "my_suptitle = rf'Normal distribution: $\\mu = {mu:.1f}$, ' + \\\n",
    "              rf'$\\sigma = {sigma:.1f}$'\n",
    "figure1.suptitle(my_suptitle, y=1.0, va='bottom', fontsize=16)\n",
    "figure1.set_size_inches(5,5)\n",
    "\n",
    "\n",
    "ndim, nsamples = 2, 100000\n",
    "#np.random.seed(42)\n",
    "# generate some synthetic data from a beta distribution\n",
    "a = 4\n",
    "b = 20\n",
    "beta_samples = stats.beta(a,b).rvs(size=ndim * nsamples) \\\n",
    "                              .reshape([nsamples, ndim])\n",
    "\n",
    "figure2 = corner.corner(beta_samples, \n",
    "                        labels=[r\"$x$\", r\"$y$\", r\"$\\log \\alpha$\"],\n",
    "                        quantiles=[0.16, 0.5, 0.84],\n",
    "                        show_titles=True, title_kwargs={\"fontsize\": 12})\n",
    "my_suptitle = rf'Beta distribution: $a = {a:.1f}$, $b = {b:.1f}$'\n",
    "figure2.suptitle(my_suptitle, y=1.0, va='bottom', fontsize=16)\n",
    "figure2.set_size_inches(5,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*What do you learn from these plots?*\n",
    "\n",
    "*Try replotting several times with only 1000 samples each and note how much the plots change.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# now more than one mode (all random)\n",
    "ndim, nsamples = 4, 50000\n",
    "np.random.seed(1234)\n",
    "data1 = np.random.randn(ndim * 4 * nsamples // 5) \\\n",
    "          .reshape([4 * nsamples // 5, ndim])\n",
    "mean = 4*np.random.rand(ndim)\n",
    "data2 = (mean[None, :] + np.random.randn(ndim * nsamples // 5) \\\n",
    "          .reshape([nsamples // 5, ndim]))\n",
    "samples = np.vstack([data1, data2])\n",
    "\n",
    "#figure = corner.corner(samples)\n",
    "figure = corner.corner(samples, labels=[r\"$x$\", r\"$y$\", r\"$\\log \\alpha$\", \\\n",
    "                                        r\"$\\Gamma \\, [\\mathrm{parsec}]$\"],\n",
    "                       quantiles=[0.16, 0.5, 0.84],\n",
    "                       show_titles=True, title_kwargs={\"fontsize\": 12})\n",
    "\n",
    "figure.set_size_inches(7,7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*What do you learn from these plots?*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}